from pymongo import MongoClient
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import logging
import time
from pymongo.errors import CursorNotFound, OperationFailure
from config import MONGO_URL

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Connect to MongoDB
client = MongoClient(MONGO_URL)
db = client['service-competence']
collection = db['fiches_metiers']

# Load the tokenizer and model
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")
tokenizer.pad_token = tokenizer.eos_token

def clean_competences(competences):
    """Clean and filter the competences generated by GPT-2."""
    cleaned = {
        "hard_skills": [],
        "soft_skills": [],
        "methodology": []
    }

    stop_words = ["transition écologique", "auxiliary", "reverse", "job category"]

    for category, skills in competences.items():
        if isinstance(skills, list):
            cleaned[category] = [
                                    skill.strip() for skill in skills
                                    if not any(stop_word in skill.lower() for stop_word in stop_words)
                                ][:40]  # Limit to 40 elements

    return cleaned

def generate_competences(properties):
    """Generate competences using the GPT-2 model."""
    try:
        input_text = (
            "Generate a structured list in JSON format with 30 to 40 complementary hard skills, soft skills, and methodologies "
            f"for the job titled '{properties.get('nom_poste', '')}' based on the following job data. "
            "The output should strictly follow this JSON format:\n"
            "{\n"
            '  "hard_skills": ["Skill 1", "Skill 2"],\n'
            '  "soft_skills": ["Skill 1", "Skill 2"],\n'
            '  "methodology": ["Methodology 1", "Methodology 2"]\n'
            "}\n"
            "\nJob Data:\n"
            f"Hard Skills: {properties.get('hard_skills', [])}\n"
            f"Soft Skills: {properties.get('soft_skills', [])}\n"
            f"Methodology: {properties.get('methodology', [])}\n"
        )
        logger.info(f"Input sent to GPT-2:\n{input_text}")

        input_ids = tokenizer.encode(input_text, return_tensors="pt", padding=True)
        attention_mask = (input_ids != tokenizer.pad_token_id).long()

        output = model.generate(
            input_ids,
            attention_mask=attention_mask,
            max_new_tokens=300,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            pad_token_id=tokenizer.pad_token_id
        )

        generated_text = tokenizer.decode(output[0], skip_special_tokens=True).strip()
        logger.info(f"Generated text:\n{generated_text}")

        # Attempt to parse the generated text as JSON
        try:
            import json
            structured_output = json.loads(generated_text)
        except json.JSONDecodeError:
            # If JSON parsing fails, use the input properties directly
            structured_output = properties

        for category in structured_output:
            structured_output[category] = structured_output[category][:40]

        return structured_output

    except Exception as e:
        logger.error(f"Error generating competences: {e}")
        return properties


def update_documents():
    """Update MongoDB documents with generated competences."""
    logger.info("Starting the update process...")

    try:
        batch_size = 100
        documents = collection.find().batch_size(batch_size)

        for document in documents:
            try:
                logger.info(f"Processing document ID: {document['_id']}...")

                properties = {
                    "nom_poste": document.get("nom_poste", ""),
                    "hard_skills": (
                            document.get("savoir_faire_data", {}).get("Production, Construction, Qualité, Logistique", []) +
                            document.get("savoir_faire_data_secondaires", {}).get("Production, Construction, Qualité, Logistique", [])
                    ),
                    "soft_skills": document.get("savoir_faire_professionnels", []),
                    "methodology": document.get("normes_procede", [])
                }

                competences = generate_competences(properties)
                cleaned_competences = clean_competences(competences)

                # Ensure the first operation is completed before proceeding
                collection.update_one(
                    {"_id": document["_id"]},
                    {"$unset": {"compétencesUpdate": ""}}
                )
                time.sleep(0.1)

                collection.update_one(
                    {"_id": document["_id"]},
                    {"$set": {"compétencesUpdate": cleaned_competences}}
                )

            except OperationFailure as e:
                logger.error(f"Operation failed for document ID {document['_id']}: {e}")
                time.sleep(1)
                continue

            except Exception as e:
                logger.error(f"Error updating document ID {document['_id']}: {e}")
                continue

    except CursorNotFound as e:
        logger.error(f"Cursor not found error: {e}")
        

    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")

    logger.info("Update process completed.")

if __name__ == "__main__":
    update_documents()
